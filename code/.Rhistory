summarize( winner = method[which.min(e)])
table(W$ssize, W$winner) %>%
prop.table(margin=1)
#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
# BIC by schedule
#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
print('Winners - BIC')
W = df %>%
group_by(ssize,ix,trial) %>%
summarize( winner = method[which.min(bic)])
table(W$ssize, W$winner) %>%
prop.table(margin=1)
#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
# e0 errors ----
#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
e0_table =
df %>%
filter(is.finite(e0_hat)) %>%
mutate(err = e0_hat - e0) %>%
group_by(ssize,method) %>%
summarize( me   = mean(err),
mae  = mean(abs(err)))
e0_table
# small summary table
e0_table %>%
pivot_longer(cols=c('mae','me')) %>%
arrange(ssize, name, method) %>%
pull(value) %>%
array(dim=c(4,2,2),
dimnames=list(levels(e0_table$method),
c('MAE','ME'),
levels(e0_table$ssize))) %>%
aperm(perm=c(2,1,3)) %>%
round(2)
# e0 winners
print('Winners - e0')
W = df %>%
mutate( e = abs(e0_hat - e0)) %>%
group_by(ssize,ix,trial) %>%
summarize( winner = method[which.min(e)])
table(W$ssize, W$winner) %>%
prop.table(margin=1)
#
# #~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
# # e60 errors ----
# #~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
e60_table =
df %>%
filter(is.finite(e60_hat)) %>%
mutate(err = e60_hat - e60) %>%
group_by(ssize,method) %>%
summarize( me   = mean(err),
mae  = mean(abs(err)))
e60_table
# small summary table
e60_table %>%
pivot_longer(cols=c('mae','me')) %>%
arrange(ssize, name, method) %>%
pull(value) %>%
array(dim=c(4,2,2),
dimnames=list(levels(e60_table$method),
c('MAE','ME'),
levels(e60_table$ssize))) %>%
aperm(perm=c(2,1,3)) %>%
round(2)
# e0 winners
print('Winners - e60')
W = df %>%
mutate( e = abs(e60_hat - e60)) %>%
group_by(ssize,ix,trial) %>%
summarize( winner = method[which.min(e)])
table(W$ssize, W$winner) %>%
prop.table(margin=1)
#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
# 45q20 experiments
#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
# true values
nqx = function(logmx, x=20, n=45) {
H = cumsum(c(0, exp(logmx)))
lx = exp(-H)
10000*(1-lx[x+1+n]/lx[x+1])
}
this_x = 20
this_n = 45
true_values = true_values %>%
mutate(q = map_dbl(logmx,nqx,x=this_x,n=this_n))
tmp = df %>%
filter(is.finite(e0_hat)) %>%
mutate(qhat = map_dbl(logmx_hat, nqx, x=this_x, n=this_n)) %>%
select(trial,ix,method,ssize, qhat) %>%
left_join(select(true_values,ix,q), by='ix')
q_table = tmp %>%
mutate(err=qhat-q) %>%
group_by(ssize, method) %>%
summarize( me = mean(err),
mae=mean(abs(err)),
mape = mean(100*abs(err/q)))
q_table
# small summary table
q_table %>%
pivot_longer(cols=c('mae','me','mape')) %>%
arrange(ssize, name, method) %>%
pull(value) %>%
array(dim=c(4,3,2),
dimnames=list(levels(q_table$method),
c('MAE','MAPE','ME'),
levels(q_table$ssize))) %>%
aperm(perm=c(2,1,3)) %>%
round(1)
print('Winners - 45q20')
W = tmp %>%
mutate( e = abs(qhat-q)) %>%
group_by(ssize,ix,trial) %>%
summarize( winner = method[which.min(e)])
table(W$ssize, W$winner) %>%
prop.table(margin=1)
# Examine the Mort1DSmooth (and other) fits
# from the big cross-validated experiment
library(tidyverse)
rm(list=ls())
#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
# load estimates and data ----
#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
nparts = 3
time_stamp = '2020-07-26-1925'
time_stamp = '2021-02-01-1831'
fname = paste0('../data/BIG-cross-validated-HMD-test-',
time_stamp,'-part-1.Rdata')
load(fname)
result = subresult
for (pt in 2:(nparts-1)) {
fname = paste0('../data/BIG-cross-validated-HMD-test-',
time_stamp,'-part-',pt,'.Rdata')
load(fname)
result = bind_rows(result, subresult)
}
fname = paste0('../data/BIG-cross-validated-HMD-test-',
time_stamp,'-part-',nparts,'.Rdata')
load(fname)
load('../data/HMD.Rdata')
# because the "ix" indices in the results now refer
# to only the limited set of HMD schedules used in the
# analysis, we have to use the "crosswalk" to
# grab the right columns from HMD_logmx as the true values
#
# For ex. if the first schedule actually used was the
# 6th column of HMD_logmx, then ix=1 actually refers to
# HMD column 6.
# re-order method and sample size to be consistent with
# what we want in the output tables (100K first, P-spline first)
df = left_join(result, crosswalk) %>%
left_join(true_values, by='ix') %>%
mutate( method =
factor(method,
levels=c('MS'      ,'D1','D2','LC'),
labels=c('P-spline','D-1','D-2','D-LC')),
ssize =
factor(sample_size,
levels=c(100000, 10000),
labels=c('Population = 100,000','Population = 10,000'))
)
#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
# # check whether all estimators converged ----
#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
ok_table =
df %>%
group_by(ssize, method) %>%
summarize(pct_ok = 100*mean(!is.na(e0_hat)),
n_ok = sum(!is.na(e0_hat)))
ok_table
#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
# much faster unnest() using
# data.table functions
# from https://www.r-bloggers.com/much-faster-unnesting-with-data-table/
#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
library(rlang)
library(data.table)
unnest_dt <- function(tbl, col) {
tbl   <- as.data.table(tbl)
col   <- ensyms(col)
clnms <- syms(setdiff(colnames(tbl), as.character(col)))
tbl   <- as.data.table(tbl)
tbl   <- eval(
expr(tbl[, as.character(unlist(!!!col)), by = list(!!!clnms)])
)
colnames(tbl) <- c(as.character(clnms), as.character(col))
tbl
}
#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
# expand by age ----
#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
long_df = df %>%
filter(is.finite(e0_hat)) %>%     # filter out the 85 non-converging cases
dplyr::select(trial:logmx_hat,method,ssize)
# use faster unnesting
long_df = unnest_dt(long_df,logmx_hat) %>%
as_tibble() %>%
transform(age=0:99) %>%
mutate(logmx_hat = as.numeric(logmx_hat))
L = true_values %>%
dplyr::select(ix,logmx) %>%
unnest(cols='logmx') %>%
transform(age=0:99)
long_df = left_join(long_df, L, by=c('ix','age')) %>%
mutate(err = logmx_hat - logmx)
#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
# ASMR errors ----
#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
mae_table =
long_df %>%
group_by(ssize,method) %>%
summarize( me   = mean(err),
mae  = mean(abs(err))
)
# small summary table
mae_table %>%
pivot_longer(cols=c('mae','me')) %>%
arrange(ssize, name, method) %>%
pull(value) %>%
array(dim=c(4,2,2),
dimnames=list(levels(mae_table$method),
c('MAE','ME'),
levels(mae_table$ssize))) %>%
aperm(perm=c(2,1,3)) %>%
round(2)
# plot mean errors by method and age
# (ugly code... :/)
#devtools::install_github("zeehio/facetscales")
library(facetscales)
scales_y <- list(
`Population = 100,000` = scale_y_continuous(limits = c(-2, 1.6)),
`Population = 10,000`  = scale_y_continuous(limits = c(-4.5, 1.7))
)
G = long_df %>%
group_by(ssize, method, age) %>%
summarize( me = mean(err),
me10 = quantile(err,.10),
me50 = quantile(err,.50),
me90 = quantile(err,.90)
) %>%
ggplot() +
aes(x=age, y=me50, color=method) +
scale_x_continuous(breaks=seq(0,100,20)) +
geom_line(size=1.5) +
geom_ribbon(aes(x=age,ymin=me10,ymax=me90, fill=method),
color=NA,alpha=.25) +
facet_grid_sc(ssize~method, scales=list(y=scales_y)) +
geom_hline(yintercept = 0) +
scale_color_manual(values=c('red','darkgreen','blue','brown')) +
scale_fill_manual(values=c('red','darkgreen','blue','brown')) +
guides(color=FALSE, fill=FALSE) +
labs(y="Median Error and 80% interval") +
theme_bw() +
theme(strip.background = element_rect(fill=grey(.90)),
strip.text=element_text(face='bold',size=15))
ggsave(filename='../plots/mean-errors-by-method-and-age.pdf',
plot=G, width=11, height=8.5)
ggsave(filename='../plots/mean-errors-by-method-and-age.eps',
device=cairo_ps,
plot=G, width=11, height=8.5)
#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
# BIC and effective df info ----
#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
bic_table =
df %>%
filter(is.finite(e0_hat)) %>%
group_by(ssize, method) %>%
summarize( median_bic = median(bic),
median_df = median(df)) %>%
dplyr::select(ssize,method,median_bic,median_df) %>%
data.frame() %>%
mutate_if(is.numeric,round,1)
# small summary table
bic_table %>%
pivot_longer(cols=c('median_bic','median_df')) %>%
arrange(ssize, name, method) %>%
pull(value) %>%
array(dim=c(4,2,2),
dimnames=list(levels(bic_table$method),
c('BIC','DF'),
levels(bic_table$ssize))) %>%
aperm(perm=c(2,1,3)) %>%
round(2)
#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
# 'winners' for total error
#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
print('Winners - Sum of Absolute Errors (all ages)')
W = long_df %>%
group_by(ssize,ix,trial,method) %>%
summarize( e  = sum(abs(err))) %>%
group_by(ssize,ix,trial) %>%
summarize( winner = method[which.min(e)])
table(W$ssize, W$winner) %>%
prop.table(margin=1)
#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
# BIC by schedule
#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
print('Winners - BIC')
W = df %>%
group_by(ssize,ix,trial) %>%
summarize( winner = method[which.min(bic)])
table(W$ssize, W$winner) %>%
prop.table(margin=1)
#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
# e0 errors ----
#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
e0_table =
df %>%
filter(is.finite(e0_hat)) %>%
mutate(err = e0_hat - e0) %>%
group_by(ssize,method) %>%
summarize( me   = mean(err),
mae  = mean(abs(err)))
e0_table
# small summary table
e0_table %>%
pivot_longer(cols=c('mae','me')) %>%
arrange(ssize, name, method) %>%
pull(value) %>%
array(dim=c(4,2,2),
dimnames=list(levels(e0_table$method),
c('MAE','ME'),
levels(e0_table$ssize))) %>%
aperm(perm=c(2,1,3)) %>%
round(2)
# e0 winners
print('Winners - e0')
W = df %>%
mutate( e = abs(e0_hat - e0)) %>%
group_by(ssize,ix,trial) %>%
summarize( winner = method[which.min(e)])
table(W$ssize, W$winner) %>%
prop.table(margin=1)
#
# #~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
# # e60 errors ----
# #~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
e60_table =
df %>%
filter(is.finite(e60_hat)) %>%
mutate(err = e60_hat - e60) %>%
group_by(ssize,method) %>%
summarize( me   = mean(err),
mae  = mean(abs(err)))
e60_table
# small summary table
e60_table %>%
pivot_longer(cols=c('mae','me')) %>%
arrange(ssize, name, method) %>%
pull(value) %>%
array(dim=c(4,2,2),
dimnames=list(levels(e60_table$method),
c('MAE','ME'),
levels(e60_table$ssize))) %>%
aperm(perm=c(2,1,3)) %>%
round(2)
# e0 winners
print('Winners - e60')
W = df %>%
mutate( e = abs(e60_hat - e60)) %>%
group_by(ssize,ix,trial) %>%
summarize( winner = method[which.min(e)])
table(W$ssize, W$winner) %>%
prop.table(margin=1)
#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
# 45q20 experiments
#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
# true values
nqx = function(logmx, x=20, n=45) {
H = cumsum(c(0, exp(logmx)))
lx = exp(-H)
10000*(1-lx[x+1+n]/lx[x+1])
}
this_x = 20
this_n = 45
true_values = true_values %>%
mutate(q = map_dbl(logmx,nqx,x=this_x,n=this_n))
tmp = df %>%
filter(is.finite(e0_hat)) %>%
mutate(qhat = map_dbl(logmx_hat, nqx, x=this_x, n=this_n)) %>%
dplyr::select(trial,ix,method,ssize, qhat) %>%
left_join(dplyr::select(true_values,ix,q), by='ix')
q_table = tmp %>%
mutate(err=qhat-q) %>%
group_by(ssize, method) %>%
summarize( me = mean(err),
mae=mean(abs(err)),
mape = mean(100*abs(err/q)))
q_table
# small summary table
q_table %>%
pivot_longer(cols=c('mae','me','mape')) %>%
arrange(ssize, name, method) %>%
pull(value) %>%
array(dim=c(4,3,2),
dimnames=list(levels(q_table$method),
c('MAE','MAPE','ME'),
levels(q_table$ssize))) %>%
aperm(perm=c(2,1,3)) %>%
round(1)
print('Winners - 45q20')
W = tmp %>%
mutate( e = abs(qhat-q)) %>%
group_by(ssize,ix,trial) %>%
summarize( winner = method[which.min(e)])
table(W$ssize, W$winner) %>%
prop.table(margin=1)
time_stamp
setwd("~/GitHub/D-spline-replication/code")
MS_nopenalty
MS_nopenalty = Mort1Dsmooth( x      = 0:99,
y      = D,
w      = w,
deg    = 3,
offset = log(N),
ndx    = 33,
method = 3,
lambda = 0)
setwd("~/GitHub/D-spline-replication/code")
#--------------------------------------------------------------
# creates a figure illustrating the unpenalized spline
# fit to simulated small-area data with Portugal 1970-1979
# female log mortality rates
#--------------------------------------------------------------
library(tidyverse)
library(MortalitySmooth)
library(splines)
rm(list = ls())
# hard-coded data ----
#' These are simulated samples from the Portugal 1970-1979
#' HMD population age structure and mortality rates
true_mx =
c(`0` = 0.03591, `1` = 0.00406, `2` = 0.00189, `3` = 0.00131,
`4` = 0.00094, `5` = 0.00074, `6` = 0.00067, `7` = 0.00053, `8` = 0.00047,
`9` = 5e-04,  `10` = 4e-04,  `11` = 0.00045, `12` = 4e-04, `13` = 0.00043,
`14` = 0.00048, `15` = 0.00047, `16` = 0.00053, `17` = 0.00055,
`18` = 0.00059, `19` = 6e-04, `20` = 6e-04, `21` = 0.00069, `22` = 0.00063,
`23` = 0.00068, `24` = 0.00073, `25` = 0.00072, `26` = 0.00078,
`27` = 0.00081, `28` = 0.00082, `29` = 0.00083, `30` = 0.00089,
`31` = 0.00098, `32` = 0.00105, `33` = 0.00109, `34` = 0.00115,
`35` = 0.00129, `36` = 0.00136, `37` = 0.0014,  `38` = 0.00167,
`39` = 0.00177, `40` = 0.00187, `41` = 0.0019,  `42` = 0.0021,
`43` = 0.00234, `44` = 0.00242, `45` = 0.00261, `46` = 0.00297,
`47` = 0.00316, `48` = 0.00357, `49` = 0.00368, `50` = 0.00416,
`51` = 0.00425, `52` = 0.00474, `53` = 0.00517, `54` = 0.00538,
`55` = 0.00593, `56` = 0.00654, `57` = 0.00684, `58` = 0.0079,
`59` = 0.00839, `60` = 0.00962, `61` = 0.01041, `62` = 0.01173,
`63` = 0.01309, `64` = 0.01459, `65` = 0.01586, `66` = 0.01788,
`67` = 0.02012, `68` = 0.02289, `69` = 0.02609, `70` = 0.02989,
`71` = 0.03326, `72` = 0.03805, `73` = 0.04374, `74` = 0.05071,
`75` = 0.05811, `76` = 0.06464, `77` = 0.07137, `78` = 0.08402,
`79` = 0.09513, `80` = 0.09406, `81` = 0.10159, `82` = 0.11712,
`83` = 0.12813, `84` = 0.1441,  `85` = 0.15551, `86` = 0.17847,
`87` = 0.19435, `88` = 0.21617, `89` = 0.23707, `90` = 0.25522,
`91` = 0.26763, `92` = 0.28701, `93` = 0.31319, `94` = 0.34524,
`95` = 0.37964, `96` = 0.4079,  `97` = 0.43677, `98` = 0.46609,
`99` = 0.49563)
N100K =
c(1718L, 1652L, 1584L, 1762L, 1691L, 1692L, 1715L, 1705L, 1654L,
1747L, 1716L, 1783L, 1665L, 1725L, 1667L, 1672L, 1655L, 1604L,
1602L, 1599L, 1487L, 1568L, 1492L, 1546L, 1405L, 1420L, 1340L,
1258L, 1260L, 1244L, 1201L, 1203L, 1197L, 1172L, 1137L, 1209L,
1234L, 1258L, 1324L, 1219L, 1281L, 1312L, 1244L, 1277L, 1269L,
1254L, 1205L, 1218L, 1179L, 1200L, 1204L, 1150L, 1148L, 1100L,
1035L, 1030L, 1083L, 1023L, 993L, 1037L, 991L, 953L, 951L, 904L,
917L, 887L, 894L, 864L, 827L, 835L, 791L, 717L, 738L, 634L, 612L,
556L, 473L, 452L, 388L, 331L, 390L, 317L, 284L, 221L, 216L, 177L,
163L, 119L, 101L, 79L, 54L, 29L, 36L, 26L, 21L, 12L, 6L, 5L,
2L, 3L)
D100K =
c(70L, 5L, 4L, 3L, 1L, 2L, 1L, 1L, 2L, 0L, 0L, 2L, 0L, 0L, 1L,
1L, 0L, 2L, 2L, 0L, 0L, 0L, 1L, 0L, 0L, 2L, 0L, 0L, 0L, 1L, 0L,
2L, 0L, 1L, 0L, 1L, 1L, 6L, 3L, 2L, 6L, 4L, 3L, 5L, 2L, 2L, 4L,
3L, 8L, 5L, 7L, 5L, 3L, 5L, 6L, 7L, 8L, 8L, 6L, 9L, 11L, 9L,
11L, 16L, 16L, 11L, 19L, 18L, 16L, 32L, 26L, 22L, 34L, 21L, 32L,
32L, 27L, 30L, 37L, 26L, 34L, 31L, 37L, 33L, 37L, 22L, 25L, 26L,
17L, 21L, 9L, 10L, 16L, 11L, 6L, 1L, 4L, 2L, 3L, 2L)
#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
# n=100,000 example second ----
#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
N = N100K
D = D100K
zero = (D==0 & N>0)
good = (D>0)
age  = 0:99
raw_data = tibble(age,true_mx,good,zero,N,D)
w = 1*(N>0) # disregard ages with zero exposure
MS_nopenalty = Mort1Dsmooth( x      = 0:99,
y      = D,
w      = w,
deg    = 3,
offset = log(N),
ndx    = 33,
method = 3,
lambda = 0)
MS_nopenalty$B
matplot(0:99, MS_nopenalty$B)
matplot(0:99, MS_nopenalty$B, type='l')
matplot(0:99, MS_nopenalty$B, type='l', col=1:4)
matplot(0:99, MS_nopenalty$B, type='l', col=1:4, lty=1)
matplot(0:99, MS_nopenalty$B, type='l', col=1:4, lty=1,lwd=2)
B = splines::bs(0:99, knots=seq(3,96,3), degree=3, intercept=TRUE)
matplot(0:99, B, type='l', col=4+1:4, lty=1,lwd=2)
B[1,]
B[2,]
B[100,]
B[4,]
B[4,]
B[1:10, 1:10] %>% round(3)
library(MortalitySmooth)
Mort1Dsmooth
Mort1Dsmooth_estimate
